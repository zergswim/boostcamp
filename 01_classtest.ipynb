{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport gc\nimport pandas as pd\n\nclass ML():\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    transforms, dataloaders, dataset_sizes, class_names = None, None, None, None\n    model, ciriterion, optimizer = None, None, None\n\n    def __init__(self, transform, model, criterion, opt, lr):\n        self.Empty()\n        self.model = model.to(self.device)\n        self.criterion = criterion\n#         self.optimizer = opt(model.fc.parameters(), lr=lr)\n        self.optimizer = opt(model.parameters(), lr=lr) #, weight_decay=0.0)\n        self.optimizer.zero_grad() #초기화\n        self.transforms = transform\n\n    def Empty(self):\n        torch.cuda.empty_cache()\n        gc.collect()        \n        \n    def Data(self, train_sets, valid_sets, batch_size=4, shuffle=True, num_workers=2):\n#         train_sets, valid_sets = datasets.ImageFolder(train_dir, self.transforms['train']), datasets.ImageFolder(valid_dir, self.transforms['valid'])\n        self.dataloaders = { 'train':DataLoader(train_sets, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers), \n                             'valid':DataLoader(valid_sets, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers) }\n        self.dataset_sizes = {'train':len(train_sets), 'valid':len(valid_sets)}\n        self.class_names = train_sets.classes\n        print(\"train: {}, valid: {}\".format(self.dataset_sizes['train'], self.dataset_sizes['valid']))\n        \n    def Train(self, num_epochs=5, empty=True, name=\"Noname\"):\n        if empty: self.Empty()\n        since = time.time()\n        for epoch in range(num_epochs):\n            print('[Epoch {}/{}]'.format(epoch+1, num_epochs))\n            for phase in ['train', 'valid']:\n                if phase == 'train': self.model.train()\n                else: self.model.eval()\n\n                running_loss, running_corrects = 0.0, 0\n                for inputs, labels in self.dataloaders[phase]:\n                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n                    outputs = self.model(inputs)\n                    loss = self.criterion(outputs, labels)\n                    if phase == 'train':\n                        self.optimizer.zero_grad()\n                        loss.backward()\n                        self.optimizer.step()\n\n                    _, preds = torch.max(outputs, 1)\n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n\n                epoch_loss, epoch_acc = running_loss / self.dataset_sizes[phase], running_corrects.double() / self.dataset_sizes[phase]\n                print('{} loss: {:.4f}, acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n                \n#     def Train2(self, num_epochs=5):\n#         since = time.time()\n#         for epoch in range(num_epochs):\n#             print('[Epoch {}/{}]'.format(epoch+1, num_epochs))\n#             for phase in ['train', 'valid']:\n#                 if phase == 'train': self.model.train()\n#                 else: self.model.eval()\n\n#                 running_loss, running_corrects = 0.0, 0\n#                 for inputs, labels in self.dataloaders[phase]:\n#                     inputs, labels = inputs.to(self.device), labels.to(self.device)\n#                     self.optimizer.zero_grad()\n#                     with torch.set_grad_enabled(phase == 'train'):# 학습 시에만 연산 기록을 추적\n#                         outputs = self.model(inputs)\n#                         _, preds = torch.max(outputs, 1)\n#                         loss = self.criterion(outputs, labels)\n#                         if phase == 'train':\n#                             loss.backward()\n#                             self.optimizer.step()\n\n#                     running_loss += loss.item() * inputs.size(0)\n#                     running_corrects += torch.sum(preds == labels.data)\n\n#                 epoch_loss, epoch_acc = running_loss / self.dataset_sizes[phase], running_corrects.double() / self.dataset_sizes[phase]\n#                 print('{} loss: {:.4f}, acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n#         time_elapsed = time.time() - since\n#         print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n                \n    def Save(self, filename):\n        torch.save(self.model.state_dict(), filename)\n        print(filename, 'saved')\n        \n    def Load(self, filename, empty=True):\n        if empty: self.Empty()\n        self.model.load_state_dict(torch.load(filename))        \n        self.model.eval()\n        print(filename, 'loaded')\n        \n    def Valid(self, show_yn=False):\n        running_corrects = 0\n        for idx, (inputs, labels) in enumerate(self.dataloaders['valid']):\n            outputs = self.model(inputs.to(self.device))\n            probs = torch.nn.Softmax(dim=1)(outputs).cpu().detach().numpy()\n            probs_max = np.max(probs, axis=1)\n            preds_max = np.argmax(probs, axis=1)\n            if show_yn and preds_max.all() != labels.numpy().all(): self.Show(inputs, preds_max, probs_max, labels)\n            running_corrects += np.sum(preds_max == labels.numpy())\n        print(\"acc {} valided\".format(running_corrects / self.dataset_sizes['valid']))\n        \n    def Show(self, inputs, preds, vals, labels, figsize=(16,4)):\n        plt.subplots(figsize=figsize)\n        for idx, i in enumerate(inputs):\n            plt.subplot(1, len(inputs), idx+1)\n            plt.imshow(i.numpy().transpose((1, 2, 0)))\n            plt.title(\"{} {} {:.2f}\".format(preds[idx]==labels[idx], self.class_names[preds[idx]], vals[idx]))\n            plt.axis('off')\n        plt.show()\n              \n    def Predict(self, test_sets):\n        test_loader = DataLoader(test_sets, shuffle=False)\n        answers = []\n        for inputs, labels in test_loader:\n            outputs = self.model(inputs.to(self.device))\n            probs = torch.nn.Softmax(dim=1)(outputs).cpu().detach().numpy()\n            answers.append(probs)\n#             answers.append(outputs.cpu().detach().numpy())\n        return answers\n        \n    def Submit(self, test_dir, filename, show_yn=False):\n        test_set = datasets.ImageFolder(test_dir, self.transforms['valid'])\n        test_loader = DataLoader(test_set, shuffle=False)\n        answers = []\n        for inputs, labels in test_loader:\n            outputs = self.model(inputs.to(self.device))\n#             vals, preds = torch.max(outputs, 1)\n            probs = torch.nn.Softmax(dim=1)(outputs).cpu().detach().numpy()\n            probs_max = np.max(probs, axis=1)\n            preds_max = np.argmax(probs, axis=1)            \n            if show_yn: self.Show(inputs, preds_max, probs_max, labels)\n            answers.extend(list(preds_max))\n\n        submit_df = pd.DataFrame({'answer_value': answers})\n        submit_df.to_csv(filename)\n        print(submit_df.value_counts())\n        print(filename, 'submited')        \n        \n#     def __str__(self):\n#         return \"dataloaders : {}\".format(self.dataloaders)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-29T02:15:27.096381Z","iopub.execute_input":"2022-09-29T02:15:27.096800Z","iopub.status.idle":"2022-09-29T02:15:27.130658Z","shell.execute_reply.started":"2022-09-29T02:15:27.096765Z","shell.execute_reply":"2022-09-29T02:15:27.129474Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# !pip install timm\nimport timm\n# print(timm.list_models(pretrained=True))\n# model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=7) #75.714\n# model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=7) #90\nmodel = timm.create_model('resnet50', pretrained=True, num_classes=7) #best 95.714","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:15:27.132879Z","iopub.execute_input":"2022-09-29T02:15:27.133284Z","iopub.status.idle":"2022-09-29T02:15:27.683801Z","shell.execute_reply.started":"2022-09-29T02:15:27.133247Z","shell.execute_reply":"2022-09-29T02:15:27.682804Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"transform = { \n    'train': transforms.Compose([ \n                        transforms.ToTensor(), \n#                         transforms.RandomVerticalFlip(),        \n#                         transforms.RandomHorizontalFlip(),        \n#                         transforms.Grayscale(num_output_channels=3),\n#                         transforms.RandomGrayscale(),\n#                         transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n#                         transforms.RandomResizedCrop(224),\n#                         transforms.Resize((224,224)),\n#                         transforms.CenterCrop(224),\n#                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n    ]),\n    'valid': transforms.Compose([ \n                        transforms.ToTensor(),\n#                         transforms.CenterCrop(224),\n#                         transforms.Grayscale(num_output_channels=3),\n#                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n    ]) }\n\n# model = models.resnet18(pretrained=True)\n# model = models.resnet50(pretrained=True)\n# model = models.resnet152(pretrained=True)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# model.fc = torch.nn.Linear(model.fc.in_features, 7) #len(self.class_names))\n# model.fc = torch.nn.Sequential(\n#     torch.nn.Linear(model.fc.in_features, 14, bias=True),\n#     torch.nn.BatchNorm1d(14),            \n#     torch.nn.ReLU(inplace=True),\n#     torch.nn.Linear(14, 7, bias=True))\n\n# train_sets = datasets.ImageFolder('/kaggle/input/testdata/train/', transform['train'])\n# valid_sets = datasets.ImageFolder('/kaggle/input/testdata2/train2/', transform['valid'])\n# ml = ML(train_sets, valid_sets, transform, batch_size=7)\n# ml.Network(model, torch.nn.CrossEntropyLoss(), torch.optim.Adam, lr=0.00005)\n# ml.Train(num_epochs=20)\n# ml.Save(\"test.ml\")","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:15:27.686276Z","iopub.execute_input":"2022-09-29T02:15:27.687142Z","iopub.status.idle":"2022-09-29T02:15:27.695071Z","shell.execute_reply.started":"2022-09-29T02:15:27.687098Z","shell.execute_reply":"2022-09-29T02:15:27.694060Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# ml.Load(\"test.ml\")\n# ml.Valid()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:15:27.698195Z","iopub.execute_input":"2022-09-29T02:15:27.698570Z","iopub.status.idle":"2022-09-29T02:15:27.709071Z","shell.execute_reply.started":"2022-09-29T02:15:27.698534Z","shell.execute_reply":"2022-09-29T02:15:27.708009Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# ml.Submit('/kaggle/input/testdata/test/', 'output.csv')#, show_yn=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:15:27.710444Z","iopub.execute_input":"2022-09-29T02:15:27.710887Z","iopub.status.idle":"2022-09-29T02:15:27.719971Z","shell.execute_reply.started":"2022-09-29T02:15:27.710830Z","shell.execute_reply":"2022-09-29T02:15:27.718768Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"#kfold 처리\nfrom sklearn.model_selection import StratifiedKFold\nfrom PIL import Image\n\nk_fold_num = 5\nbatch_size = 7\nnum_epochs = 5\n\n#kfold return 의 idx처리를 위해 DataFrame 용 커스텀데이터셋 정의\nclass MyDataset(Dataset):\n    def __init__(self, df, transform=None, classes=None):\n        self.df, self.transform, self.classes = df, transform, classes\n    def __getitem__(self, idx):\n        data = self.df.iloc[idx]\n        image = Image.open(data['img_path'])\n        if self.transform: image = self.transform(image)\n        return image, data['label']\n    def __len__(self): return len(self.df)    \n\nsets = datasets.ImageFolder('/kaggle/input/testdata/train/', transform['train'])\nkfold = StratifiedKFold(n_splits=k_fold_num)\n\n\ndf = pd.DataFrame(sets.imgs, columns=('img_path','label'))\n\n# 클래스 별로 이미지 수가 다르기 때문에 imbalance 문제를 완화하기 위해 가장 많은 클래스 이미지 수 / 각 클래스 이미지 수로 나눈 값을 가중치로 사용.\n# class_num = [329, 205, 235, 134, 151, 245, 399]\n# class_weight = torch.tensor(np.max(class_num) / class_num).to(device='cuda:0', dtype=torch.float)\n\nfor i, (train_index, valid_index) in enumerate(kfold.split(sets.imgs, sets.targets)):\n    \n    print(f\"\\n** Fold_{i} **\")\n    train_sets = MyDataset(df.iloc[train_index], transform['train'], sets.classes)\n    valid_sets = MyDataset(df.iloc[valid_index], transform['valid'], sets.classes)\n    ml = ML(transform, model, torch.nn.CrossEntropyLoss(), torch.optim.Adam, lr=0.00005)\n    ml.Data(train_sets, valid_sets, batch_size=batch_size)\n    ml.Train(num_epochs=num_epochs, name=f\"Fold_{i}\")\n    ml.Save(\"train_fold_{}.ml\".format(i))","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:15:27.724049Z","iopub.execute_input":"2022-09-29T02:15:27.724766Z","iopub.status.idle":"2022-09-29T02:21:30.296955Z","shell.execute_reply.started":"2022-09-29T02:15:27.724738Z","shell.execute_reply":"2022-09-29T02:21:30.295601Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"\n** Fold_0 **\ntrain: 1358, valid: 340\n[Epoch 1/5]\ntrain loss: 1.8475, acc: 0.3100\nvalid loss: 1.7339, acc: 0.4382\n[Epoch 2/5]\ntrain loss: 1.5476, acc: 0.4389\nvalid loss: 1.3706, acc: 0.6147\n[Epoch 3/5]\ntrain loss: 1.1694, acc: 0.6303\nvalid loss: 0.9101, acc: 0.7882\n[Epoch 4/5]\ntrain loss: 0.8348, acc: 0.7879\nvalid loss: 0.5248, acc: 0.9029\n[Epoch 5/5]\ntrain loss: 0.5556, acc: 0.8697\nvalid loss: 0.2756, acc: 0.9441\nTraining complete in 1m 12s\ntrain_fold_0.ml saved\n\n** Fold_1 **\ntrain: 1358, valid: 340\n[Epoch 1/5]\ntrain loss: 0.3979, acc: 0.9116\nvalid loss: 0.1170, acc: 0.9853\n[Epoch 2/5]\ntrain loss: 0.3399, acc: 0.9028\nvalid loss: 0.0802, acc: 0.9882\n[Epoch 3/5]\ntrain loss: 0.2570, acc: 0.9308\nvalid loss: 0.0657, acc: 0.9882\n[Epoch 4/5]\ntrain loss: 0.2118, acc: 0.9418\nvalid loss: 0.0583, acc: 0.9912\n[Epoch 5/5]\ntrain loss: 0.1990, acc: 0.9426\nvalid loss: 0.0768, acc: 0.9882\nTraining complete in 1m 12s\ntrain_fold_1.ml saved\n\n** Fold_2 **\ntrain: 1358, valid: 340\n[Epoch 1/5]\ntrain loss: 0.1699, acc: 0.9543\nvalid loss: 0.0274, acc: 1.0000\n[Epoch 2/5]\ntrain loss: 0.1574, acc: 0.9558\nvalid loss: 0.0195, acc: 1.0000\n[Epoch 3/5]\ntrain loss: 0.1296, acc: 0.9669\nvalid loss: 0.0177, acc: 1.0000\n[Epoch 4/5]\ntrain loss: 0.1106, acc: 0.9742\nvalid loss: 0.0203, acc: 1.0000\n[Epoch 5/5]\ntrain loss: 0.0837, acc: 0.9831\nvalid loss: 0.0168, acc: 1.0000\nTraining complete in 1m 11s\ntrain_fold_2.ml saved\n\n** Fold_3 **\ntrain: 1359, valid: 339\n[Epoch 1/5]\ntrain loss: 0.0801, acc: 0.9831\nvalid loss: 0.0089, acc: 0.9971\n[Epoch 2/5]\ntrain loss: 0.0844, acc: 0.9801\nvalid loss: 0.0082, acc: 1.0000\n[Epoch 3/5]\ntrain loss: 0.0739, acc: 0.9794\nvalid loss: 0.0112, acc: 1.0000\n[Epoch 4/5]\ntrain loss: 0.0656, acc: 0.9845\nvalid loss: 0.0114, acc: 0.9971\n[Epoch 5/5]\ntrain loss: 0.0444, acc: 0.9904\nvalid loss: 0.0115, acc: 0.9971\nTraining complete in 1m 12s\ntrain_fold_3.ml saved\n\n** Fold_4 **\ntrain: 1359, valid: 339\n[Epoch 1/5]\ntrain loss: 0.0411, acc: 0.9919\nvalid loss: 0.0042, acc: 1.0000\n[Epoch 2/5]\ntrain loss: 0.0501, acc: 0.9890\nvalid loss: 0.0047, acc: 1.0000\n[Epoch 3/5]\ntrain loss: 0.0436, acc: 0.9897\nvalid loss: 0.0039, acc: 1.0000\n[Epoch 4/5]\ntrain loss: 0.0394, acc: 0.9919\nvalid loss: 0.0048, acc: 1.0000\n[Epoch 5/5]\ntrain loss: 0.0297, acc: 0.9934\nvalid loss: 0.0045, acc: 1.0000\nTraining complete in 1m 12s\ntrain_fold_4.ml saved\n","output_type":"stream"}]},{"cell_type":"code","source":"#ensemble 처리\n# ml = ML(transform, model, torch.nn.CrossEntropyLoss(), torch.optim.Adam, lr=0.00005)\n# ml.Data(train_sets, valid_sets, batch_size=batch_size)\n\ntest_sets = datasets.ImageFolder('/kaggle/input/testdata/test/', transform['valid'])\nlen_img, len_classes = len(test_sets.imgs), len(test_sets.classes)\nrst = [[np.zeros(len_classes)] for i in range(len_img)]\n\nfor i in range(k_fold_num):\n    ml.Load(\"train_fold_{}.ml\".format(i))\n#     ml.Valid(show_yn=True)\n    rtn = ml.Predict(test_sets)\n    for idx, r in enumerate(rtn):\n        rst[idx] += r #probs sum\n#         r = r.flatten()\n#         rst[idx] += np.array([1 if max(r)==i else 0 for i in r]) #voting","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:21:30.298893Z","iopub.execute_input":"2022-09-29T02:21:30.299650Z","iopub.status.idle":"2022-09-29T02:21:52.791596Z","shell.execute_reply.started":"2022-09-29T02:21:30.299603Z","shell.execute_reply":"2022-09-29T02:21:52.790524Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"train_fold_0.ml loaded\ntrain_fold_1.ml loaded\ntrain_fold_2.ml loaded\ntrain_fold_3.ml loaded\ntrain_fold_4.ml loaded\n","output_type":"stream"}]},{"cell_type":"code","source":"answers = [np.argmax(r/len_classes) for r in rst]\n# answers = [np.argmax(r) for r in rst]\nprint(answers)\nsubmission_df = pd.DataFrame({'answer_value': answers})\nsubmission_df.to_csv('kflod.csv')\nsubmission_df.value_counts()\n\n#kfold best, 98.57","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:21:52.793512Z","iopub.execute_input":"2022-09-29T02:21:52.795214Z","iopub.status.idle":"2022-09-29T02:21:52.819102Z","shell.execute_reply.started":"2022-09-29T02:21:52.795164Z","shell.execute_reply":"2022-09-29T02:21:52.817918Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"[2, 3, 3, 3, 3, 3, 4, 0, 3, 1, 6, 2, 0, 2, 3, 1, 2, 0, 6, 3, 3, 5, 2, 3, 0, 5, 1, 2, 0, 5, 4, 5, 6, 2, 0, 5, 5, 4, 2, 1, 4, 0, 2, 3, 1, 3, 0, 5, 5, 2, 6, 5, 4, 1, 5, 0, 4, 5, 1, 1, 5, 0, 6, 1, 1, 2, 4, 1, 1, 3, 2, 3, 0, 1, 1, 6, 2, 0, 3, 4, 1, 6, 1, 6, 6, 4, 3, 6, 1, 2, 2, 5, 1, 0, 5, 6, 3, 3, 1, 6, 5, 6, 6, 0, 3, 2, 5, 3, 0, 0, 4, 6, 2, 5, 4, 2, 0, 0, 5, 6, 4, 2, 2, 6, 4, 1, 5, 6, 0, 4, 1, 1, 6, 4, 4, 2, 5, 6, 5, 0, 4, 3, 1, 5, 0, 5, 4, 0, 2, 5, 6, 1, 6, 3, 2, 2, 0, 1, 4, 5, 2, 4, 6, 2, 3, 4, 1, 5, 6, 2, 1, 5, 3, 1, 0, 3, 2, 5, 3, 4, 2, 0, 3, 6, 0, 3, 3, 2, 0, 4, 4, 2, 2, 4, 4, 6, 6, 6, 3, 2, 5, 5, 4, 6, 2, 1, 3, 6, 0, 2, 3, 1, 1, 3, 1, 5, 2, 2, 0, 0, 0, 1, 2, 2, 2, 6, 3, 2, 5, 4, 3, 5, 0, 2, 4, 5, 0, 6, 4, 1, 6, 1, 2, 1, 6, 0, 5, 4, 6, 3, 4, 2, 5, 3, 1, 4, 2, 3, 4, 0, 6, 0, 2, 0, 1, 4, 1, 4, 0, 1, 1, 5, 6, 4, 6, 2, 4, 4, 3, 6, 6, 4, 0, 3, 3, 3, 0, 0, 5, 2, 5, 5, 2, 5, 2, 6, 5, 1, 5, 1, 5, 3, 0, 3, 3, 1, 6, 5, 0, 2, 0, 4, 3, 4, 4, 2, 5, 1, 2, 0, 6, 6, 1, 3, 3, 0, 0, 5, 2, 4, 6, 6, 6, 3, 6, 0, 4, 6, 4, 0, 2, 0, 5, 5, 1, 6, 3, 3, 5, 1]\n","output_type":"stream"},{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"answer_value\n2               55\n3               51\n0               50\n5               50\n6               50\n1               48\n4               46\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# pseudo labeling\nsets = datasets.ImageFolder('/kaggle/input/testdata/train/', transform['train'])\ntest_sets = datasets.ImageFolder('/kaggle/input/testdata/test/', transform['train'])\n\ndf_sets = pd.DataFrame(sets.imgs, columns=('img_path','label'))\ndf_test_sets = pd.DataFrame(test_sets.imgs, columns=('img_path','label'))\ndf_test_sets['label'] = answers\ndf_pseudo = pd.concat([df_sets, df_test_sets])\npseudo_sets = MyDataset(df_pseudo, transform['train'], sets.classes)\n\nml = ML(transform, model, torch.nn.CrossEntropyLoss(), torch.optim.Adam, lr=0.00005)\nml.Data(pseudo_sets, valid_sets, batch_size=batch_size)\nml.Train(num_epochs=num_epochs)\nml.Save(\"train_pseudo_labeling.ml\")","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:21:52.820842Z","iopub.execute_input":"2022-09-29T02:21:52.821462Z","iopub.status.idle":"2022-09-29T02:23:37.565324Z","shell.execute_reply.started":"2022-09-29T02:21:52.821413Z","shell.execute_reply":"2022-09-29T02:23:37.563957Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"train: 2048, valid: 339\n[Epoch 1/5]\ntrain loss: 0.0683, acc: 0.9800\nvalid loss: 0.0035, acc: 1.0000\n[Epoch 2/5]\ntrain loss: 0.0566, acc: 0.9829\nvalid loss: 0.0039, acc: 1.0000\n[Epoch 3/5]\ntrain loss: 0.0468, acc: 0.9907\nvalid loss: 0.0039, acc: 1.0000\n[Epoch 4/5]\ntrain loss: 0.0445, acc: 0.9888\nvalid loss: 0.0034, acc: 1.0000\n[Epoch 5/5]\ntrain loss: 0.0301, acc: 0.9907\nvalid loss: 0.0044, acc: 1.0000\nTraining complete in 1m 44s\ntrain_pseudo_labeling.ml saved\n","output_type":"stream"}]},{"cell_type":"code","source":"ml.Load(\"train_pseudo_labeling.ml\")\n\n# ml.Valid(show_yn=True)\nml.Submit('/kaggle/input/testdata/test/', 'pseudo_labeling.csv')#, show_yn=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T02:23:37.569520Z","iopub.execute_input":"2022-09-29T02:23:37.569885Z","iopub.status.idle":"2022-09-29T02:23:42.118208Z","shell.execute_reply.started":"2022-09-29T02:23:37.569841Z","shell.execute_reply":"2022-09-29T02:23:42.117112Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"train_pseudo_labeling.ml loaded\nanswer_value\n2               55\n3               51\n0               50\n5               50\n6               50\n1               48\n4               46\ndtype: int64\npseudo_labeling.csv submited\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}